# Day 4: Introduction to 3D Rendering

## Overview

Today we enter the third dimension! We'll learn how to cast rays from a camera and test for intersections with 3D objects. We'll start with analytical methods (solving equations directly) for spheres and tori, then transition to raymarching with signed distance functions—a more flexible approach that enables complex procedural scenes.

By the end of today, you'll understand:
- How to set up a camera and generate rays for each pixel
- Analytical ray-object intersection for simple surfaces
- Why analytical methods become challenging for complex geometry
- Signed distance functions as an alternative representation
- The raymarching algorithm (sphere tracing)
- How to compose multiple objects and assign materials

---

## Part 1: Analytical Ray Tracing

### Camera and Ray Setup

#### The Rendering Pipeline

For each pixel, we need to:
1. Generate a ray from the camera through that pixel
2. Find where (if anywhere) the ray intersects scene geometry
3. Compute color based on surface properties and lighting

#### Coordinate System

We'll use the standard graphics convention:
- **Y-axis** points up
- **Z-axis** points toward the camera (out of the screen)
- **X-axis** points right
- Right-handed coordinate system

#### Pinhole Camera Model

Our camera sits at the origin looking down the negative Z-axis. For a pixel at normalized coordinates $(u, v) \in [-1, 1]^2$, we generate a ray:

**Ray origin:** $\mathbf{o} = (0, 0, 0)$ (camera position)  
**Ray direction:** $\mathbf{d} = \text{normalize}(u, v, -f)$

where $f$ is the focal length, related to field of view by: $f = 1/\tan(\text{FOV}/2)$.

#### Parametric Ray Equation

A ray can be written as:
$$\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}$$

where $t \geq 0$ is the parameter. Points along the ray correspond to different values of $t$.

#### Implementation

Let's start by visualizing our rays without any intersections:

**Shader 1: Ray Visualization**
```glsl
void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // Normalize pixel coordinates to [-1, 1]
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    
    // Correct for aspect ratio
    uv.x *= iResolution.x / iResolution.y;
    
    // Field of view
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    // Ray direction (camera at origin, looking down -Z)
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    // Color based on ray direction (visualize the rays)
    vec3 color = rayDir * 0.5 + 0.5;
    
    fragColor = vec4(color, 1.0);
}
```

You should see a colorful gradient showing the direction of each ray. This confirms our camera setup is working!

---

### Ray-Sphere Intersection

#### The Sphere Equation

A sphere of radius $r$ centered at position $\mathbf{c}$ is defined by:
$$|\mathbf{p} - \mathbf{c}|^2 = r^2$$

All points $\mathbf{p}$ satisfying this equation lie on the sphere's surface.

#### Finding the Intersection

We want to find where our ray $\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}$ intersects the sphere. Substituting the ray equation into the sphere equation:
$$|\mathbf{o} + t\mathbf{d} - \mathbf{c}|^2 = r^2$$

Let $\mathbf{oc} = \mathbf{o} - \mathbf{c}$ (vector from sphere center to ray origin). Expanding:
$$|\mathbf{oc} + t\mathbf{d}|^2 = r^2$$
$$|\mathbf{oc}|^2 + 2t(\mathbf{oc} \cdot \mathbf{d}) + t^2|\mathbf{d}|^2 = r^2$$

This is a quadratic equation in $t$:
$$at^2 + bt + c = 0$$

where:
- $a = |\mathbf{d}|^2$ (equals 1 if direction is normalized)
- $b = 2(\mathbf{oc} \cdot \mathbf{d})$
- $c = |\mathbf{oc}|^2 - r^2$

The **discriminant** $\Delta = b^2 - 4ac$ tells us:
- $\Delta < 0$: no intersection (ray misses sphere)
- $\Delta = 0$: one intersection (ray grazes sphere)
- $\Delta > 0$: two intersections (ray enters and exits)

We want the smaller positive $t$ (the entry point).

#### Implementation

**Shader 2: Basic Sphere**
```glsl
float intersectSphere(vec3 rayOrigin, vec3 rayDir, vec3 sphereCenter, float radius) {
    vec3 oc = rayOrigin - sphereCenter;
    
    float a = dot(rayDir, rayDir);  // Should be 1.0 if rayDir is normalized
    float b = 2.0 * dot(oc, rayDir);
    float c = dot(oc, oc) - radius * radius;
    
    float discriminant = b * b - 4.0 * a * c;
    
    if (discriminant < 0.0) {
        return -1.0;  // No intersection
    }
    
    // Return the closer intersection
    float t1 = (-b - sqrt(discriminant)) / (2.0 * a);
    float t2 = (-b + sqrt(discriminant)) / (2.0 * a);
    
    // Return closest positive t
    if (t1 > 0.0) return t1;
    if (t2 > 0.0) return t2;
    return -1.0;  // Both behind camera
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // Setup ray
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    // Sphere parameters
    vec3 sphereCenter = vec3(0.0, 0.0, -3.0);
    float sphereRadius = 1.0;
    
    // Test intersection
    float t = intersectSphere(rayOrigin, rayDir, sphereCenter, sphereRadius);
    
    vec3 color;
    if (t > 0.0) {
        // Hit the sphere
        color = vec3(1.0, 0.0, 0.0);  // Red
    } else {
        // Background
        color = vec3(0.1, 0.1, 0.2);  // Dark blue
    }
    
    fragColor = vec4(color, 1.0);
}
```

You should see a flat red disk! It looks 2D because we don't have lighting yet—we can't see the sphere's curvature.

---

### Adding Lighting

To see the 3D structure, we need to compute lighting based on the **surface normal**.

#### Surface Normal

For a sphere centered at $\mathbf{c}$, the outward normal at surface point $\mathbf{p}$ is:
$$\mathbf{n} = \frac{\mathbf{p} - \mathbf{c}}{r}$$

This is just the vector from center to surface, normalized.

#### Diffuse Lighting

The simplest lighting model: **Lambertian diffuse shading**. Surface brightness depends on the angle between the normal $\mathbf{n}$ and light direction $\mathbf{l}$:
$$\text{brightness} = \max(0, \mathbf{n} \cdot \mathbf{l})$$

The $\max(0, \cdots)$ ensures surfaces facing away from the light remain dark.

**Shader 3: Sphere with Lighting**
```glsl
float intersectSphere(vec3 rayOrigin, vec3 rayDir, vec3 sphereCenter, float radius) {
    vec3 oc = rayOrigin - sphereCenter;
    float a = dot(rayDir, rayDir);
    float b = 2.0 * dot(oc, rayDir);
    float c = dot(oc, oc) - radius * radius;
    float discriminant = b * b - 4.0 * a * c;
    
    if (discriminant < 0.0) return -1.0;
    
    float t1 = (-b - sqrt(discriminant)) / (2.0 * a);
    float t2 = (-b + sqrt(discriminant)) / (2.0 * a);
    
    if (t1 > 0.0) return t1;
    if (t2 > 0.0) return t2;
    return -1.0;
}

vec3 sphereNormal(vec3 hitPoint, vec3 sphereCenter, float radius) {
    return (hitPoint - sphereCenter) / radius;
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // Setup ray
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    // Sphere
    vec3 sphereCenter = vec3(0.0, 0.0, -3.0);
    float sphereRadius = 1.0;
    
    float t = intersectSphere(rayOrigin, rayDir, sphereCenter, sphereRadius);
    
    vec3 color;
    if (t > 0.0) {
        // Hit point
        vec3 hitPoint = rayOrigin + t * rayDir;
        
        // Surface normal
        vec3 normal = sphereNormal(hitPoint, sphereCenter, sphereRadius);
        
        // Light direction (from above and to the right)
        vec3 lightDir = normalize(vec3(1.0, 1.0, 1.0));
        
        // Diffuse lighting
        float diffuse = max(0.0, dot(normal, lightDir));
        
        // Sphere color
        vec3 sphereColor = vec3(1.0, 0.0, 0.0);  // Red
        color = sphereColor * diffuse;
        
        // Add ambient light so dark side isn't completely black
        color += sphereColor * 0.1;
    } else {
        color = vec3(0.1, 0.1, 0.2);
    }
    
    fragColor = vec4(color, 1.0);
}
```

Now the sphere looks 3D! The lighting reveals its curvature. Beautiful!

---

### Ray-Torus Intersection: Where Analytical Gets Complex

#### The Torus Equation

A torus with major radius $R$ (distance from center to tube center) and minor radius $r$ (tube thickness) has the implicit equation:
$$\left(\sqrt{x^2 + z^2} - R\right)^2 + y^2 = r^2$$

Or in vector form:
$$\left(|\mathbf{p}_{xz}| - R\right)^2 + p_y^2 = r^2$$

where $\mathbf{p}_{xz} = (p_x, p_z)$ is the projection onto the XZ-plane.

#### The Challenge

Substituting our ray equation into this gives a **quartic polynomial** (degree 4):
$$at^4 + bt^3 + ct^2 + dt + e = 0$$

Unlike quadratics (which have a simple formula), quartic equations require sophisticated algebraic methods. Here's what solving it actually looks like:

**Shader 4: Analytical Torus**
```glsl
// From Inigo Quilez - https://www.shadertoy.com/view/XdSGWy
// Analytical quartic solver for torus intersection
float intersectTorus(vec3 ro, vec3 rd, vec2 tor)
{
    float po = 1.0;
    float Ra2 = tor.x * tor.x;
    float ra2 = tor.y * tor.y;
    
    float m = dot(ro, ro);
    float n = dot(ro, rd);
    
    // Bounding sphere check
    float h = n*n - m + (tor.x + tor.y) * (tor.x + tor.y);
    if(h < 0.0) return -1.0;
    
    // Find quartic coefficients
    float k = (m - ra2 - Ra2) / 2.0;
    float k3 = n;
    float k2 = n*n + Ra2*rd.z*rd.z + k;
    float k1 = k*n + Ra2*ro.z*rd.z;
    float k0 = k*k + Ra2*ro.z*ro.z - Ra2*ra2;
    
    // Prevent numerical issues
    if(abs(k3*(k3*k3 - k2) + k1) < 0.01)
    {
        po = -1.0;
        float tmp = k1; k1 = k3; k3 = tmp;
        k0 = 1.0/k0;
        k1 = k1*k0;
        k2 = k2*k0;
        k3 = k3*k0;
    }
    
    float c2 = 2.0*k2 - 3.0*k3*k3;
    float c1 = k3*(k3*k3 - k2) + k1;
    float c0 = k3*(k3*(-3.0*k3*k3 + 4.0*k2) - 8.0*k1) + 4.0*k0;
    
    c2 /= 3.0;
    c1 *= 2.0;
    c0 /= 3.0;
    
    float Q = c2*c2 + c0;
    float R = 3.0*c0*c2 - c2*c2*c2 - c1*c1;
    
    float h2 = R*R - Q*Q*Q;
    float z = 0.0;
    
    if(h2 < 0.0)
    {
        // 4 intersections
        float sQ = sqrt(Q);
        z = 2.0*sQ*cos(acos(R/(sQ*Q)) / 3.0);
    }
    else
    {
        // 2 intersections
        float sQ = pow(sqrt(h2) + abs(R), 1.0/3.0);
        z = sign(R)*abs(sQ + Q/sQ);
    }
    
    z = c2 - z;
    
    float d1 = z - 3.0*c2;
    float d2 = z*z - 3.0*c0;
    
    if(abs(d1) < 1.0e-4)
    {
        if(d2 < 0.0) return -1.0;
        d2 = sqrt(d2);
    }
    else
    {
        if(d1 < 0.0) return -1.0;
        d1 = sqrt(d1/2.0);
        d2 = c1/d1;
    }
    
    float result = 1e20;
    
    h2 = d1*d1 - z + d2;
    if(h2 > 0.0)
    {
        h2 = sqrt(h2);
        float t1 = -d1 - h2 - k3;
        float t2 = -d1 + h2 - k3;
        t1 = (po < 0.0) ? 2.0/t1 : t1;
        t2 = (po < 0.0) ? 2.0/t2 : t2;
        if(t1 > 0.0) result = t1;
        if(t2 > 0.0) result = min(result, t2);
    }
    
    h2 = d1*d1 - z - d2;
    if(h2 > 0.0)
    {
        h2 = sqrt(h2);
        float t1 = d1 - h2 - k3;
        float t2 = d1 + h2 - k3;
        t1 = (po < 0.0) ? 2.0/t1 : t1;
        t2 = (po < 0.0) ? 2.0/t2 : t2;
        if(t1 > 0.0) result = min(result, t1);
        if(t2 > 0.0) result = min(result, t2);
    }
    
    return result;
}

vec3 torusNormal(vec3 pos, vec2 tor)
{
    return normalize(pos * (dot(pos,pos) - tor.y*tor.y - tor.x*tor.x*vec3(1.0,1.0,-1.0)));
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // Setup ray
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    // Torus parameters
    vec2 torus = vec2(1.0, 0.4);  // (major radius, minor radius)
    vec3 torusCenter = vec3(0.0, 0.0, -3.5);
    
    // Adjust ray for torus position
    vec3 ro = rayOrigin - torusCenter;
    
    float t = intersectTorus(ro, rayDir, torus);
    
    vec3 color;
    if (t > 0.0) {
        vec3 hitPoint = ro + t * rayDir;
        vec3 normal = torusNormal(hitPoint, torus);
        
        vec3 lightDir = normalize(vec3(1.0, 1.0, 1.0));
        float diffuse = max(0.0, dot(normal, lightDir));
        
        vec3 torusColor = vec3(0.0, 0.7, 1.0);  // Cyan
        color = torusColor * diffuse + torusColor * 0.1;
    } else {
        color = vec3(0.1, 0.1, 0.2);
    }
    
    fragColor = vec4(color, 1.0);
}
```

Look at that intersection code! Over 80 lines of complex algebra just to render one torus. And this is still a relatively simple surface—imagine arbitrary algebraic varieties, or trying to combine multiple objects with boolean operations.

Analytical methods work beautifully for simple geometry, but we need a more flexible approach for complex scenes.

---

## Part 2: Signed Distance Functions and Raymarching

### Introduction to SDFs

A **signed distance function** (SDF) gives the distance from any point in space to the nearest surface:

$$d(\mathbf{p}) = \begin{cases}
> 0 & \text{outside surface} \\
= 0 & \text{on surface} \\
< 0 & \text{inside surface}
\end{cases}$$

Crucially, $|d(\mathbf{p})|$ is the actual Euclidean distance to the surface.

#### Why SDFs?

SDFs have a powerful property: if we're at point $\mathbf{p}$ and the surface is distance $d$ away, we can safely move $d$ units in *any* direction without hitting anything. This enables **sphere tracing**—we march along the ray taking steps proportional to the SDF value.

#### SDF Examples

Let's see SDFs for shapes we've already rendered analytically:

**Sphere:**
```glsl
float sdSphere(vec3 p, vec3 center, float radius) {
    return length(p - center) - radius;
}
```

Compare this to our 30+ line analytical intersection! Much simpler.

**Torus:**
```glsl
float sdTorus(vec3 p, vec3 center, float majorRadius, float minorRadius) {
    vec3 q = p - center;
    vec2 pxz = vec2(q.x, q.z);
    float d = length(pxz) - majorRadius;
    return length(vec2(d, q.y)) - minorRadius;
}
```

Again, dramatically simpler than the quartic solver!

**Other Primitives**

Many more SDFs exist: boxes, cylinders, capsules, cones, pyramids, etc. See [Inigo Quilez's comprehensive library](https://iquilezles.org/articles/distfunctions/) for a complete reference. Each SDF is typically just a few lines of code.

---

### The Raymarching Algorithm

**Sphere tracing** works like this:

1. Start at the ray origin
2. Evaluate the SDF at current position
3. March forward along the ray by that distance (safe step!)
4. Repeat until:
   - Very close to surface (SDF ≈ 0) → hit!
   - Too far away → miss
   - Too many steps → give up

Here's the algorithm:
```glsl
float sceneSDF(vec3 p) {
    // Define scene geometry (we'll implement this)
    return 0.0;
}

bool raymarch(vec3 rayOrigin, vec3 rayDir, out float hitDist, out vec3 hitPos) {
    float t = 0.0;
    
    for(int i = 0; i < 100; i++) {
        vec3 pos = rayOrigin + t * rayDir;
        float d = sceneSDF(pos);
        
        // Close enough to surface?
        if(abs(d) < 0.001) {
            hitDist = t;
            hitPos = pos;
            return true;
        }
        
        // March forward
        t += d;
        
        // Too far?
        if(t > 100.0) {
            return false;
        }
    }
    
    return false;
}
```

#### Normal Estimation via Gradient

For an SDF $d(\mathbf{p})$, the gradient $\nabla d$ points perpendicular to the surface (it's the normal direction). We estimate it using finite differences:

$$\frac{\partial d}{\partial x} \approx \frac{d(x + \epsilon, y, z) - d(x - \epsilon, y, z)}{2\epsilon}$$
```glsl
vec3 estimateNormal(vec3 p) {
    float eps = 0.001;
    float dx = sceneSDF(p + vec3(eps, 0, 0)) - sceneSDF(p - vec3(eps, 0, 0));
    float dy = sceneSDF(p + vec3(0, eps, 0)) - sceneSDF(p - vec3(0, eps, 0));
    float dz = sceneSDF(p + vec3(0, 0, eps)) - sceneSDF(p - vec3(0, 0, eps));
    return normalize(vec3(dx, dy, dz));
}
```

#### First Raymarch Shader

**Shader 5: Single Sphere with Raymarching**
```glsl
float sdSphere(vec3 p, vec3 center, float radius) {
    return length(p - center) - radius;
}

float sceneSDF(vec3 p) {
    return sdSphere(p, vec3(0.0, 0.0, -3.0), 1.0);
}

vec3 estimateNormal(vec3 p) {
    float eps = 0.001;
    float dx = sceneSDF(p + vec3(eps, 0, 0)) - sceneSDF(p - vec3(eps, 0, 0));
    float dy = sceneSDF(p + vec3(0, eps, 0)) - sceneSDF(p - vec3(0, eps, 0));
    float dz = sceneSDF(p + vec3(0, 0, eps)) - sceneSDF(p - vec3(0, 0, eps));
    return normalize(vec3(dx, dy, dz));
}

bool raymarch(vec3 rayOrigin, vec3 rayDir, out vec3 hitPos) {
    float t = 0.0;
    
    for(int i = 0; i < 100; i++) {
        vec3 pos = rayOrigin + t * rayDir;
        float d = sceneSDF(pos);
        
        if(abs(d) < 0.001) {
            hitPos = pos;
            return true;
        }
        
        t += d;
        
        if(t > 100.0) return false;
    }
    
    return false;
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    // Setup ray
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    // Raymarch
    vec3 hitPos;
    bool hit = raymarch(rayOrigin, rayDir, hitPos);
    
    vec3 color;
    if(hit) {
        vec3 normal = estimateNormal(hitPos);
        vec3 lightDir = normalize(vec3(1.0, 1.0, 1.0));
        float diffuse = max(0.0, dot(normal, lightDir));
        
        vec3 sphereColor = vec3(1.0, 0.0, 0.0);
        color = sphereColor * diffuse + sphereColor * 0.1;
    } else {
        color = vec3(0.1, 0.1, 0.2);
    }
    
    fragColor = vec4(color, 1.0);
}
```

Same result as the analytical sphere, but now we have a flexible framework!

---

### The Power of SDFs: Instant Shape Swapping

Here's where SDFs shine: **changing shapes is trivial**. Just swap out one SDF for another!

**Shader 6: Shapeshifting**
```glsl
float sdSphere(vec3 p, vec3 center, float radius) {
    return length(p - center) - radius;
}

float sdTorus(vec3 p, vec3 center, float majorRadius, float minorRadius) {
    vec3 q = p - center;
    vec2 pxz = vec2(q.x, q.z);
    float d = length(pxz) - majorRadius;
    return length(vec2(d, q.y)) - minorRadius;
}

float sdBox(vec3 p, vec3 center, vec3 halfExtents) {
    vec3 q = abs(p - center) - halfExtents;
    return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0);
}

float sceneSDF(vec3 p) {
    // Uncomment ONE of these to see different shapes!
    // Everything else stays the same - same raymarch, same lighting, same normal calculation
    
    return sdSphere(p, vec3(0.0, 0.0, -3.0), 1.0);
    //return sdTorus(p, vec3(0.0, 0.0, -3.0), 1.0, 0.4);
    //return sdBox(p, vec3(0.0, 0.0, -3.0), vec3(0.8, 0.8, 0.8));
    
    // Try any SDF from https://iquilezles.org/articles/distfunctions/
}

vec3 estimateNormal(vec3 p) {
    float eps = 0.001;
    float dx = sceneSDF(p + vec3(eps, 0, 0)) - sceneSDF(p - vec3(eps, 0, 0));
    float dy = sceneSDF(p + vec3(0, eps, 0)) - sceneSDF(p - vec3(0, eps, 0));
    float dz = sceneSDF(p + vec3(0, 0, eps)) - sceneSDF(p - vec3(0, 0, eps));
    return normalize(vec3(dx, dy, dz));
}

bool raymarch(vec3 rayOrigin, vec3 rayDir, out vec3 hitPos) {
    float t = 0.0;
    
    for(int i = 0; i < 100; i++) {
        vec3 pos = rayOrigin + t * rayDir;
        float d = sceneSDF(pos);
        
        if(abs(d) < 0.001) {
            hitPos = pos;
            return true;
        }
        
        t += d;
        if(t > 100.0) return false;
    }
    
    return false;
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    vec3 hitPos;
    bool hit = raymarch(rayOrigin, rayDir, hitPos);
    
    vec3 color;
    if(hit) {
        vec3 normal = estimateNormal(hitPos);
        vec3 lightDir = normalize(vec3(1.0, 1.0, 1.0));
        float diffuse = max(0.0, dot(normal, lightDir));
        
        vec3 objectColor = vec3(0.0, 0.7, 1.0);  // Cyan
        color = objectColor * diffuse + objectColor * 0.1;
    } else {
        color = vec3(0.1, 0.1, 0.2);
    }
    
    fragColor = vec4(color, 1.0);
}
```

Comment/uncomment different SDFs in `sceneSDF()` to instantly see different shapes! Try adding more from Quilez's library. The raymarching algorithm doesn't care what shape you use—it just follows the distance field.

---

### Composing Multiple Objects

To combine multiple objects, we simply take the **minimum distance** to any object. The closest surface wins!

**Shader 7: Multiple Objects with Materials**
```glsl
float sdSphere(vec3 p, vec3 center, float radius) {
    return length(p - center) - radius;
}

float sdTorus(vec3 p, vec3 center, float majorRadius, float minorRadius) {
    vec3 q = p - center;
    vec2 pxz = vec2(q.x, q.z);
    float d = length(pxz) - majorRadius;
    return length(vec2(d, q.y)) - minorRadius;
}

float sdPlane(vec3 p, float height) {
    return p.y - height;
}

// Global variable to track which object we hit
float gMaterialID;

float sceneSDF(vec3 p) {
    float d = 1e10;  // Start with very large distance
    
    // Sphere
    float sphere = sdSphere(p, vec3(-1.2, 0.0, -3.5), 0.8);
    if(sphere < d) {
        d = sphere;
        gMaterialID = 1.0;
    }
    
    // Torus
    float torus = sdTorus(p, vec3(1.2, 0.0, -3.5), 1.0, 0.3);
    if(torus < d) {
        d = torus;
        gMaterialID = 2.0;
    }
    
    // Ground plane
    float plane = sdPlane(p, -1.0);
    if(plane < d) {
        d = plane;
        gMaterialID = 3.0;
    }
    
    return d;
}

vec3 getMaterialColor(float matID) {
    if(matID < 1.5) return vec3(1.0, 0.0, 0.0);      // Sphere: red
    if(matID < 2.5) return vec3(0.0, 0.7, 1.0);      // Torus: cyan
    return vec3(0.5, 0.5, 0.5);                       // Plane: gray
}

vec3 estimateNormal(vec3 p) {
    float eps = 0.001;
    float dx = sceneSDF(p + vec3(eps, 0, 0)) - sceneSDF(p - vec3(eps, 0, 0));
    float dy = sceneSDF(p + vec3(0, eps, 0)) - sceneSDF(p - vec3(0, eps, 0));
    float dz = sceneSDF(p + vec3(0, 0, eps)) - sceneSDF(p - vec3(0, 0, eps));
    return normalize(vec3(dx, dy, dz));
}

bool raymarch(vec3 rayOrigin, vec3 rayDir, out vec3 hitPos, out float matID) {
    float t = 0.0;
    
    for(int i = 0; i < 100; i++) {
        vec3 pos = rayOrigin + t * rayDir;
        float d = sceneSDF(pos);
        
        if(abs(d) < 0.001) {
            hitPos = pos;
            matID = gMaterialID;
            return true;
        }
        
        t += d;
        if(t > 100.0) return false;
    }
    
    return false;
}

void mainImage(out vec4 fragColor, in vec2 fragCoord)
{
    vec2 uv = (fragCoord / iResolution.xy) * 2.0 - 1.0;
    uv.x *= iResolution.x / iResolution.y;
    
    float fov = 45.0;
    float focalLength = 1.0 / tan(radians(fov) / 2.0);
    
    vec3 rayOrigin = vec3(0.0, 0.0, 0.0);
    vec3 rayDir = normalize(vec3(uv.x, uv.y, -focalLength));
    
    vec3 hitPos;
    float matID;
    bool hit = raymarch(rayOrigin, rayDir, hitPos, matID);
    
    vec3 color;
    if(hit) {
        vec3 normal = estimateNormal(hitPos);
        vec3 lightDir = normalize(vec3(1.0, 1.0, 1.0));
        float diffuse = max(0.0, dot(normal, lightDir));
        
        vec3 objectColor = getMaterialColor(matID);
        color = objectColor * diffuse + objectColor * 0.1;
    } else {
        color = vec3(0.1, 0.1, 0.2);
    }
    
    fragColor = vec4(color, 1.0);
}
```

Three objects with different colors! Adding more objects is trivial—just add another SDF check in `sceneSDF()`. Compare this to analytical methods where combining objects requires sophisticated CSG (constructive solid geometry) techniques.

---

## Summary

Today we learned two approaches to 3D rendering:

**Analytical Ray Tracing:**
- Solve equations directly for ray-surface intersection
- Exact solutions, very efficient for simple geometry
- Sphere: straightforward quadratic equation
- Torus: complex quartic equation requiring sophisticated algebra
- Becomes increasingly difficult for complex surfaces
- Standard in production ray tracers for well-defined geometry

**SDF-Based Raymarching:**
- Represent surfaces as distance fields
- March along rays using sphere tracing
- Simple, uniform code for any geometry
- Easy composition: just take minimum distance
- Flexible—works for procedural, implicit, or arbitrary surfaces
- Slightly slower than analytical, but much more versatile

**Key Concepts:**
- Camera setup and ray generation
- Parametric ray equation: $\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}$
- Surface normals for lighting
- Diffuse (Lambertian) shading
- Signed distance functions (SDFs)
- Sphere tracing algorithm
- Normal estimation via gradient (finite differences)
- Material tracking for multiple objects

Tomorrow we'll explore advanced raymarching: domain operations for infinite repetition, boolean operations for smooth blending, and 3D fractals!

---

## Homework

### Required: Algebraic Variety Rendering

Implement analytical ray tracing for an interesting polynomial implicit surface.

**Goal:** Experience the challenges of analytical methods firsthand, then appreciate SDFs even more!

**Suggested surfaces:**
- **Degree 3**: Saddle surfaces, cubic varieties
- **Degree 4**: Klein bottle projections, quartic surfaces with interesting topology
- **Cassini ovals** in 3D: $(x^2 + y^2 + z^2)^2 - 2a^2(x^2 - y^2) = b^4 - a^4$

**Implementation steps:**

1. **Define your implicit function** $F(x,y,z) = 0$

Example—a quartic surface:
```glsl
float implicitFunction(vec3 p) {
    float r2 = dot(p, p);
    return r2 * r2 - (p.x*p.x + p.y*p.y - 2.0*p.z*p.z);
}
```

2. **Implement root finding** (bisection method)
```glsl
float intersectImplicit(vec3 rayOrigin, vec3 rayDir) {
    float tMin = 0.0;
    float tMax = 10.0;
    
    // Check for sign change
    float fMin = implicitFunction(rayOrigin + tMin * rayDir);
    float fMax = implicitFunction(rayOrigin + tMax * rayDir);
    
    if(fMin * fMax > 0.0) return -1.0;  // No root
    
    // Bisection
    for(int i = 0; i < 50; i++) {
        float tMid = (tMin + tMax) / 2.0;
        float fMid = implicitFunction(rayOrigin + tMid * rayDir);
        
        if(abs(fMid) < 0.001) return tMid;
        
        if(fMin * fMid < 0.0) {
            tMax = tMid;
            fMax = fMid;
        } else {
            tMin = tMid;
            fMin = fMid;
        }
    }
    
    return (tMin + tMax) / 2.0;
}
```

3. **Compute normal via gradient**
```glsl
vec3 implicitNormal(vec3 p) {
    float eps = 0.001;
    float dx = implicitFunction(p + vec3(eps, 0, 0)) - implicitFunction(p - vec3(eps, 0, 0));
    float dy = implicitFunction(p + vec3(0, eps, 0)) - implicitFunction(p - vec3(0, eps, 0));
    float dz = implicitFunction(p + vec3(0, 0, eps)) - implicitFunction(p - vec3(0, 0, eps));
    return normalize(vec3(dx, dy, dz));
}
```

4. **Optimization: Bounding volume** (optional but recommended)

Use a bounding sphere to avoid checking the entire ray:
```glsl
// First check if ray intersects bounding sphere
// Only compute implicit function if inside bounds
```

**Expected output:** A rendered algebraic surface with proper lighting showing its geometric features.

**Reflection question:** After implementing this, compare the effort to using SDFs. Which approach would you prefer for a complex scene with many objects?

---

### Optional Exercises

#### 1. Specular Lighting (Phong Model)

Add shiny highlights using the Phong reflection model:

$$\text{specular} = (R \cdot V)^n$$

where $R$ is reflected light direction, $V$ is view direction, $n$ is shininess.
```glsl
vec3 R = reflect(-lightDir, normal);  // Reflected light
vec3 V = -rayDir;                      // View direction
float spec = pow(max(0.0, dot(R, V)), 32.0);
color += vec3(1.0) * spec * 0.5;  // White specular highlight
```

Try different shininess values (8, 16, 32, 64, 128) to see the effect!

#### 2. Camera Movement

Implement an orbiting camera using time:
```glsl
float angle = iTime * 0.5;
vec3 rayOrigin = vec3(3.0 * cos(angle), 1.0, 3.0 * sin(angle));

// Look-at matrix
vec3 target = vec3(0.0, 0.0, -3.0);
vec3 forward = normalize(target - rayOrigin);
vec3 right = normalize(cross(vec3(0, 1, 0), forward));
vec3 up = cross(forward, right);

// Transform ray direction
vec3 rd = normalize(uv.x * right + uv.y * up + focalLength * forward);
```

#### 3. Complex SDF Scene

Create a scene with 5+ objects using different SDFs from [Quilez's library](https://iquilezles.org/articles/distfunctions/):
- Mix primitives: spheres, boxes, cylinders, tori, cones
- Position them creatively
- Use different materials
- Add interesting lighting

#### 4. Soft Shadows (Preview of Day 5)

Cast rays from the surface toward the light to check for occlusion:
```glsl
float softShadow(vec3 pos, vec3 lightDir) {
    float t = 0.01;  // Start slightly above surface
    float shadow = 1.0;
    
    for(int i = 0; i < 50; i++) {
        float d = sceneSDF(pos + lightDir * t);
        shadow = min(shadow, 8.0 * d / t);  // Penumbra factor
        t += d;
        if(t > 10.0 || d < 0.001) break;
    }
    
    return clamp(shadow, 0.0, 1.0);
}
```

Apply this to your diffuse lighting for more realistic shadows!

---

## Looking Ahead to Day 5

Tomorrow we'll explore advanced raymarching techniques that would be nearly impossible with analytical methods:

- **Domain operations**: Infinite repetition, symmetry, twisting
- **Boolean operations**: Union, intersection, smooth blending
- **3D fractals**: Menger sponge, Mandelbulb via iterated transformations
- **Advanced lighting**: Ambient occlusion, global illumination

Make sure you're comfortable with:
- The raymarching algorithm (it's the foundation)
- How SDFs compose (taking minimum/maximum)
- Normal estimation via gradients
- The material tracking pattern we developed

See you tomorrow!